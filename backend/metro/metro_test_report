import pandas as pd
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
from fpdf import FPDF

# Load test dataset
test_file_path = "metro_test_data.csv"  # Ensure this file exists
df_test = pd.read_csv(test_file_path)

# Load trained XGBoost model
model_path = "xgboost_metro_model.pkl"  # Ensure the trained model exists
model = joblib.load(model_path)
print("✅ Model loaded successfully.")

# Print expected vs actual features
print("✅ Model was trained on:", model.feature_names_in_)
print("✅ Test dataset contains:", df_test.columns.tolist())

# Ensure test dataset matches training features
df_test = df_test[[col for col in model.feature_names_in_ if col in df_test.columns]]  # Select only valid columns

# Load saved label encoders or recreate them
try:
    label_encoders = joblib.load("label_encoders.pkl")  # Ensure this file exists from training
except FileNotFoundError:
    from sklearn.preprocessing import LabelEncoder
    label_encoders = {}
    city_categories = ["Delhi", "Mumbai", "Bangalore", "Hyderabad", "Chennai", "Kolkata"]
    label_encoders["City"] = LabelEncoder()
    label_encoders["City"].fit(city_categories)
    risk_categories = ["Low", "Medium", "High"]
    label_encoders["Risk Level"] = LabelEncoder()
    label_encoders["Risk Level"].fit(risk_categories)
    print("✅ Label encoders recreated successfully.")

# Encode categorical columns
categorical_cols = ["City"]
for col in categorical_cols:
    df_test[col] = label_encoders[col].transform(df_test[col])

# Make predictions
predictions = model.predict(df_test)

# Decode risk levels (convert back to 'Low', 'Medium', 'High')
df_test["Predicted Risk Level"] = label_encoders["Risk Level"].inverse_transform(predictions)

# Save predictions to a CSV file
output_file = "metro_test_predictions.csv"
df_test.to_csv(output_file, index=False)
print(f"✅ Predictions saved to '{output_file}'")

# Generate risk level distribution plot
plt.figure(figsize=(8, 5))
sns.countplot(x=df_test["Predicted Risk Level"], palette="coolwarm")
plt.title("Predicted Risk Level Distribution")
plt.xlabel("Risk Level")
plt.ylabel("Count")
plt.savefig("risk_distribution.png")
plt.close()

# Generate PDF report
pdf = FPDF()
pdf.set_auto_page_break(auto=True, margin=15)
pdf.add_page()
pdf.set_font("Arial", "B", 16)
pdf.cell(200, 10, "Metro Project Risk Analysis Report", ln=True, align="C")
pdf.ln(10)

pdf.set_font("Arial", size=12)
pdf.cell(0, 10, "Summary of Predictions", ln=True, align="L")
pdf.ln(5)

# Count of risk levels
risk_counts = df_test["Predicted Risk Level"].value_counts()
for level, count in risk_counts.items():
    pdf.cell(0, 10, f"{level}: {count} projects", ln=True)

pdf.ln(10)

# Add risk distribution plot
pdf.cell(0, 10, "Predicted Risk Level Distribution", ln=True, align="L")
pdf.image("risk_distribution.png", x=10, w=180)
pdf.ln(10)

# Detailed Predictions
pdf.cell(0, 10, "Sample Predictions", ln=True, align="L")
pdf.ln(5)
for i in range(min(10, len(df_test))):
    pdf.cell(0, 10, f"Project {i+1} - City: {df_test.iloc[i]['City']}, Risk Level: {df_test.iloc[i]['Predicted Risk Level']}", ln=True)
pdf.ln(10)

# Save PDF
pdf.output("metro_test_report.pdf")
print("✅ PDF report generated: metro_test_report.pdf")
